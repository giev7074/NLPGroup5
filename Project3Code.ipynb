{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48346131-57ae-4d2b-9f6e-df6e9e046e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if any import errors occur\n",
    "#! pip install datasets transformers\n",
    "#! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a2f13c-6b75-4175-959f-88a010dc60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#Collecting all imports\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "#Transformers should be at least 4.11.0 required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981651e-ff6d-4d98-9519-4eb0cf2e0bd2",
   "metadata": {},
   "source": [
    "We must now load the dataset from our local JSON files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74b3a79-e6d1-4eda-903b-64123e120ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The ranger and the rustler both were riding horses that galloped at the same speed.  The rustler left at 01:00 where as the ranger left at 0500 hours. Who has traveled further?? \n",
      "O1: the ranger\n",
      "O2: the rustler\n",
      "A: Option 2\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset as train, validation, and test.\n",
    "#We use the dev data as validation.\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={'train':'Project/QQA_Data/QQA_train.json', \n",
    "                                           'validation':'Project/QQA_Data/QQA_dev.json', \n",
    "                                           'test':'Project/QQA_Data/QQA_test.json'})\n",
    "\n",
    "#Printing the dataset contents\n",
    "print('Q: ' + datasets['train'][0]['question'])\n",
    "print('O1: ' + datasets['train'][0]['Option1'])\n",
    "print('O2: ' + datasets['train'][0]['Option2'])\n",
    "print('A: ' + datasets['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcaace2-8030-4319-bc42-5ed145b06744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question_sci_10E_char', 'question_mask', 'Option1', 'Option2', 'type', 'question_sci_10E', 'answer', 'question', 'question_char'],\n",
       "        num_rows: 564\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_sci_10E_char', 'question_mask', 'Option1', 'Option2', 'type', 'question_sci_10E', 'answer', 'question', 'question_char'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question_sci_10E_char', 'question_mask', 'Option1', 'Option2', 'type', 'question_sci_10E', 'answer', 'question', 'question_char'],\n",
       "        num_rows: 162\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print dataset structure\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa20a-caaf-4610-924e-676a7be967b6",
   "metadata": {},
   "source": [
    "The imported data is of the form:\n",
    "\n",
    "{\"question\": \"Jame's mother has a photo of Jane standing at a height of 14 inches, whereas a mountain appears to have height of 26 cm. It looks that way because? \", \"Option1\": \"the mountain was farther away\", \"Option2\": \"Jane was farther away\", \"answer\": \"Option 2\", \"type\": \"Type_3\", \"question_sci_10E\": \"Jame's mother has a photo of Jane standing at a height of 1.4000000000E+01 inches, whereas a mountain appears to have height of 2.6000000000E+01 cm. It looks that way because? \", \"question_char\": \"Jame's mother has a photo of Jane standing at a height of 1 4 inches, whereas a mountain appears to have height of 2 6 cm. It looks that way because? \", \"question_sci_10E_char\": \"Jame's mother has a photo of Jane standing at a height of 1 . 4 0 0 0 0 0 0 0 0 0 E + 0 1 inches, whereas a mountain appears to have height of 2 . 6 0 0 0 0 0 0 0 0 0 E + 0 1 cm. It looks that way because? \", \"question_mask\": \"Jame's mother has a photo of Jane standing at a height of [Num] inches, whereas a mountain appears to have height of [Num] cm. It looks that way because? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9435d4a-07ed-4765-9b9e-f164e90c573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get rid of the other columns\n",
    "datasets = datasets.remove_columns(['question_char', 'question_sci_10E',\n",
    "                         'question_sci_10E_char',\n",
    "                         'question_mask', 'type',])\n",
    "\n",
    "#We now only have a question, answer, and 2 options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc7f584-de67-4956-b749-06e886d81b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming for compatibility later\n",
    "datasets = datasets.rename_column('answer', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5147-a707-4d31-8bd7-98a2f593ba82",
   "metadata": {},
   "source": [
    "For evaluation, see https://huggingface.co/spaces/evaluate-metric/accuracy\n",
    "\n",
    "For fine-tuning, see: https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer\n",
    "\n",
    "For handing multiple choice, see https://huggingface.co/docs/transformers/en/tasks/multiple_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a3e901-9c1c-4676-80d9-0f5f75404d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set correct answer to an integer. \n",
    "\n",
    "def set_labels(example):\n",
    "    #print(example)\n",
    "    example[\"label\"] = int(example[\"label\"][-1]) - 1\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f364ab20-e1da-4ca8-a7d0-a3bbb6d5a949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Option1': 'race car',\n",
       " 'Option2': 'pickup',\n",
       " 'label': 1,\n",
       " 'question': 'A race car and a pickup both drove on the highway at the same speed. The driver of the race car got tired and parked after 29 mins, while the driver of the pickup ran for 43 mins. Which vehicle ultimately went the greater distance?? '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e251187a-8ecc-4a47-9e5a-9ad0df35ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 4049, 1012, 102, 2023, 2003, 1037, 4946, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "tokenizer(\"This is a boat.\", \"This is a plane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6f8fda-78af-4194-8f2d-a7cf9c2854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"Option1\", \"Option2\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence two times to go with the two possibilities of second sentences.\n",
    "    first_sentences = [[context] * 2 for context in examples[\"question\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    question_headers = examples[\"question\"]\n",
    "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
    "    \n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b34511-0436-4d34-8a75-d70dbbc41ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [89, 90]\n"
     ]
    }
   ],
   "source": [
    "examples = datasets[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc11911-b731-4c65-8120-7a4ad4aa778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? [SEP] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? the tank will speed up faster than the toy car [SEP]',\n",
       " '[CLS] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? [SEP] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? the toy car will speed up faster than the tank [SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bef0f7-7a5d-43c5-9fcb-fd4ec41cf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_datasets = datasets.map(preprocess_function, batched=True)\n",
    "#print(encoded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7c4b4f-c37a-423c-b5aa-f6aa6d56f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70edf3e-ddec-4110-9888-5dfaa6b89cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e1bd0e-18f9-4c18-8404-ec91609ac08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing stuff. Be sure to create encoded_datasets if you're running this. \n",
    "#accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "#features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "#batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "#[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02763447-68f9-448c-93fc-b2f030126e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the F1 score metric to evaluate our predictions. \n",
    "\n",
    "#Old evaluator.\n",
    "'''\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}\n",
    "'''\n",
    "\n",
    "#New evaluator.\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    \n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": f1_score(label_ids, preds, average='micro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93099c3-efa5-4dc0-832b-2dad3d393318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The ranger and the rustler both were riding horses that galloped at the same speed.  The rustler left at 01:00 where as the ranger left at 0500 hours. Who has traveled further?? \n",
      "O1: the ranger\n",
      "O2: the rustler\n",
      "A: Option 2\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Option1', 'Option2', 'label', 'question'],\n",
      "        num_rows: 564\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Option1', 'Option2', 'label', 'question'],\n",
      "        num_rows: 81\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Option1', 'Option2', 'label', 'question'],\n",
      "        num_rows: 162\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# A cell to reset the dataset if/when problems occur with it.\n",
    "# Probably good to run this if you ran the above cells, since there's a lot of testing stuff for one model\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={'train':'Project/QQA_Data/QQA_train.json', \n",
    "                                           'validation':'Project/QQA_Data/QQA_dev.json', \n",
    "                                           'test':'Project/QQA_Data/QQA_test.json'})\n",
    "\n",
    "#Printing the dataset contents\n",
    "print('Q: ' + datasets['train'][0]['question'])\n",
    "print('O1: ' + datasets['train'][0]['Option1'])\n",
    "print('O2: ' + datasets['train'][0]['Option2'])\n",
    "print('A: ' + datasets['train'][0]['answer'])\n",
    "\n",
    "#Let's get rid of the other columns\n",
    "datasets = datasets.remove_columns(['question_char', 'question_sci_10E',\n",
    "                         'question_sci_10E_char',\n",
    "                         'question_mask', 'type',])\n",
    "\n",
    "#We now only have a question, answer, and 2 options.\n",
    "\n",
    "datasets = datasets.rename_column('answer', 'label')\n",
    "\n",
    "def set_labels(example):\n",
    "    #print(example)\n",
    "    example[\"label\"] = int(example[\"label\"][-1]) - 1\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(set_labels)\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1187dac7-b9c6-4c60-b26f-b28ba10d4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function. Duplicate and change model name for other models.\n",
    "\n",
    "modelName = \"\"\n",
    "\n",
    "def autoTrain(model_name = 'bert-base-uncased', batch_size = 16):\n",
    "    global model\n",
    "    global tokenizer\n",
    "    global modelName\n",
    "    modelName = model_name\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    \n",
    "    encoded_datasets = datasets.map(preprocess_function, batched=True)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        f\"{model_name}-finetuned-QQA\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=encoded_datasets[\"train\"],\n",
    "        eval_dataset=encoded_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a012d073-cddd-4ae3-ab6c-aefc648d22cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Option1', 'Option2', 'label', 'question'],\n",
      "    num_rows: 162\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Cell for testing\n",
    "print(datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a1871d6-93e8-4158-8875-093decb96888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example prediction\n",
    "\n",
    "prompt = \"I have 5 bagels and Joe has 2. Who has more bagels?\"\n",
    "candidate1 = \"Me\"\n",
    "candidate2 = \"Joe\"\n",
    "\n",
    "\n",
    "inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
    "labels = torch.tensor(0).unsqueeze(0)\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = logits.argmax().item()\n",
    "predicted_class\n",
    "\n",
    "#Note that it will output a 0 or 1, where 0 = Option 1 and 1 = Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23131c0b-4967-462a-a357-11bf5ce60a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval the most recently trained model\n",
    "def evaluate_hf_model():\n",
    "\n",
    "    global model\n",
    "    global tokenizer\n",
    "\n",
    "            \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Get predictions, and save corresponding reference (if we were using the whole dataset, we wouldn't need this step)\n",
    "    for ex in datasets[\"test\"]:\n",
    "\n",
    "        #Based on the above cell, get \n",
    "        prompt = ex['question']\n",
    "        candidate1 = ex['Option1']\n",
    "        candidate2 = ex['Option2']\n",
    "        \n",
    "        inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        predicted_class = logits.argmax().item()\n",
    "        predicted_class\n",
    "\n",
    "\n",
    "        predictions.append(predicted_class)\n",
    "        references.append(ex['label'])\n",
    "\n",
    "    # Compute metrics\n",
    "    global modelName\n",
    "    print('Performance of {} : {}'.format(modelName, f1_score(references, predictions, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94f6b934-2ac4-4ed8-9851-6190e2abc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEval(model_name, batch_size):\n",
    "    autoTrain(model_name, batch_size)\n",
    "    #eval_hf_model evaluates whatever model we just trained because of global variables. \n",
    "    #As such we have it eval after training.\n",
    "    evaluate_hf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a7c809-1c79-404a-bf3e-27264b648617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95913a99f54b43cba55bcd141e6f4323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 2:01:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693395</td>\n",
       "      <td>0.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692629</td>\n",
       "      <td>0.543210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of bert-base-uncased : 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "#Training and evaluating bert-base-uncased\n",
    "trainAndEval(\"bert-base-uncased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f783e4e2-54f4-4697-b34e-fe2bfbee0ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f3decaf004f91aabc2423895f39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda9aafbaa0b4d88bf6953973dd1841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db55b6dbecc44f1a86eb76b178c7ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe60bdebc45431da733c5b0f667aa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61e87f2eab04b45be2ad43c6483a966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e5fd438c5b48ec8b25770f842d0d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d602f75b640988f98584c3f400721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0be4aa38b14c269905764c4d40465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 2:11:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698733</td>\n",
       "      <td>0.530864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.750790</td>\n",
       "      <td>0.567901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of cardiffnlp/twitter-roberta-base-sentiment-latest : 0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a92285ba-4939-4bdf-859d-ff9ef94b9003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52d1bcbd78c4336b9d1a0e1d2e2a483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e44cf78d91b4c019cfbfffeeb6d186d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505a4fe80b5c4faea61b99994b45a42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac51f52198f4270be588ab684c64b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e71f545e074db6b8fc2e01c09a64db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d8a040be194f068601f86093fd1b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103b87759f7a4842a6d6d7acd4bdfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba85c289f0841bbaf9611b0896f6872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 1:04:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693211</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693783</td>\n",
       "      <td>0.432099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694439</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of distilbert/distilbert-base-uncased : 0.4876543209876543\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"distilbert/distilbert-base-uncased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c65d8b82-b654-4fe6-ac2d-11c64af3644e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fc8ab17c024a05a52995066d818ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--dccuchile--bert-base-spanish-wwm-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc8fa48a6be457e838d049d0878e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccd4c7c4c514234a643a9767064b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeaa52345214aaea9866add4c9697f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004d98b6efae476aad5a5bc8446d4b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f0e5e403f146bd9c829b8cc37ced59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061c3290d1ae49278ba7c7d868cc0b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4638f6f270a4566b1d88caba6d5df1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c58cc82d64315afcf15c328d62b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 3:06:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693796</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693794</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693537</td>\n",
       "      <td>0.382716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of dccuchile/bert-base-spanish-wwm-cased : 0.5493827160493827\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"dccuchile/bert-base-spanish-wwm-cased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c4a2907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf3945ae934469ab7a2d741b3bf04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7865a0b4494b508d007869acf39efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d61aade60d461aac0f169428285793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d3be8836514eb3ac84829e33addbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f393ec28fdc422ab59c2fac7c226165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868b3d53c6f94dd9aa4b2661f21b6830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b12ce791554e288e071783fd1ad49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be148a0a4344dda93eaca8441e07640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576a79126ed740bca33b1ca6a2516d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 1:55:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694271</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692599</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of deepset/roberta-base-squad2 : 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('deepset/roberta-base-squad2', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a955ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca697634ecf443b29bc95c58c655b2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--Intel--dynamic_tinybert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3038a8ace74b929377d4b0b417bb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at Intel/dynamic_tinybert and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288e20a8ae274d839e59f7b0eba52069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/351 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3fa0bf96a442509da3e882ca9f813e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9938136aa2b245f1876c0494223f433a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01b95927da141cf8888f47d266fae60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b3af760564106b6c79f707985ca2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4319f8c254e5eab5b87da633e2976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44552eff56ee41c6a71506cfc6878a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 51:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693223</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693255</td>\n",
       "      <td>0.432099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Intel/dynamic_tinybert : 0.5\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('Intel/dynamic_tinybert', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78e72be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-cased-distilled-squad and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c602b6cd94bf6956694e3b0440f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc7497b6f34e7f92f3e05ac264b055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf74d4f69d34ac6a12479ad05d36b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 53:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693228</td>\n",
       "      <td>0.469136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697462</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of distilbert/distilbert-base-cased-distilled-squad : 0.47530864197530864\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('distilbert/distilbert-base-cased-distilled-squad', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5cbe83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at FabianWillner/distilbert-base-uncased-finetuned-squad and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62004523d8b34bf68ae051722fede712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d19509e6941485e96763b4202c30dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9422cbd620d74bb2983b68db13bb99a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 53:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693158</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693034</td>\n",
       "      <td>0.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693060</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of FabianWillner/distilbert-base-uncased-finetuned-squad : 0.4691358024691358\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('FabianWillner/distilbert-base-uncased-finetuned-squad', 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ea691-1d91-4377-b132-cfea9edd10e5",
   "metadata": {},
   "source": [
    "# Comparison:\n",
    "\n",
    "The models that we evaluated were the following:\n",
    "\n",
    "Baseline:\n",
    "\n",
    "The baseline model, bert-base-uncased, and its variants. Most are designed for masked langauge modeling with similar training data, so that the only major differences are the architecture of the transformer. Some, however, use different training data. \n",
    "\n",
    "- bert-base-uncased, trained on a large corpus of unlabeled data with the objective of masked language modeling and next sentence prediction. Because there are no \"special\" features in this version of BERT, and because of its ubiquity, it is used as a baseline for other models to be compared to in this project. https://huggingface.co/google-bert/bert-base-uncased\n",
    "- distilbert-base-uncased, trained on the same data as the regular bert-base-uncased. It is smaller and faster than regular BERT, and provides an example of how reducing the number of parameters (from 110M to 67M) affects a model's ability to preform QQA. Notably, distilbert trained faster, at 0.18 it/s instead of the regular BERT's 0.08 it/s. https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "- bert-base-spanish-wwm-cased, trained on a large corpus of Spanish data. Used as an example of how training data may affect a model's ability to preform QQA. Notably, fine-tuning this model took much more time than regular BERT, with it training at a rate of 0.03 it/s. https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased\n",
    "\n",
    "Sentiment Analysis Models:\n",
    "\n",
    "Models designed for sentiment analysis. \n",
    "\n",
    "- cardiffnlp/twitter-roberta-base-sentiment-latest, a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. As this is trained for sentiment analysis, it'll provide insight into how being fine-tuned for another task beforehand affects a model's ability to preform QQA. It will also serve as the baseline for the sentiment analysis models as it contains no other notable features.\n",
    "- https://huggingface.co/siebert/sentiment-roberta-large-english (In progress)\n",
    "- https://huggingface.co/MilaNLProc/feel-it-italian-sentiment (In progress)\n",
    "\n",
    "\n",
    "All models were fine-tuned on the QQA dataset for 3 epochs with a batch size of 16, and evaluated using the evaluate_hf_model() function afterward. For evaluation, the scikit F1 micro score was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3818375-0070-4401-a42a-dee04698704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the name and accuracy to avoid having to redo everything all the time.\n",
    "#Also good for graphing. \n",
    "\n",
    "#Names are shortened to be readable on the graphs.\n",
    "modelNameAcc = [\n",
    "    #Baseline, masked language\n",
    "    [\"bert\", 0.5185185185185185],\n",
    "    [\"distilbert\", 0.49382716049382713],\n",
    "    [\"bert-base-spanish\", 0.5432098765432098],\n",
    "\n",
    "    \n",
    "    #Sentiment Analysis\n",
    "    [\"twitter-roberta\", 0.47530864197530864]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21a7cafa-d78a-4bfb-8335-3727ac3f37fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot model names, accuracies, on a graph for easy comparison\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#X points for plotting\n",
    "xpoints = np.linspace(1, len(modelNameAcc), len(modelNameAcc))\n",
    "ypoints = np.zeros(len(modelNameAcc))\n",
    "\n",
    "countModels = 0\n",
    "names = []\n",
    "for k in range(len(modelNameAcc)):\n",
    "    model, acc = modelNameAcc[k]\n",
    "    countModels += 1\n",
    "    ypoints[k] = acc\n",
    "    names.append(model)\n",
    "\n",
    "#Set plot and plot\n",
    "plt.xticks(xpoints, names)\n",
    "plt.scatter(xpoints, ypoints)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0711f-7fc9-4784-81c1-1537b1eccdce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
